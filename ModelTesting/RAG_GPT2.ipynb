{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385eb51f",
   "metadata": {},
   "source": [
    "# Integrated the trained conversational model with RAG\n",
    "\n",
    "- **Authors:** Riyaadh Gani and Damilola Ogunleye\n",
    "- **Project:** Food Recognition & Recipe LLM  \n",
    "- **Purpose:** Creating VectorDB of recipe data and combining with RAG for the model\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is used for inference of our conversational model with our RAG pipeline\n",
    "\n",
    "**Output:** Functional model for recipe support: based on Recipe NLG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f82db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: faiss-cpu in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: sentence_transformers in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: peft==0.11.1 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: tqdm in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from peft==0.11.1) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from peft==0.11.1) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from peft==0.11.1) (6.0.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from peft==0.11.1) (1.12.0)\n",
      "Requirement already satisfied: safetensors in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from peft==0.11.1) (0.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from peft==0.11.1) (0.36.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from sentence_transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from sentence_transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from sentence_transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from sentence_transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy faiss-cpu sentence_transformers transformers torch peft==0.11.1 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b3fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dogun/Documents/UCL YEAR 3/deeplearning/deeplearnvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68db84a",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "Memory management is not easy! so load the model and then change to GPU to free up CPU RAM --> then load the data and the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72429062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load conversational finetuned GPT-2 model\n",
    "model_path = '../finetune_llm/models/base/gpt2-medium'   \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    dtype=torch.float16,  # Half precision\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946c221",
   "metadata": {},
   "source": [
    "Have to load the base model + the adapter to actually access the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = '../finetune_llm/models/gpt2-conversational-v1/final'\n",
    "print(f\"Loading adapter from: {adapter_path}\")\n",
    "conversational_model = PeftModel.from_pretrained(base_model, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pad token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66421c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "conversational_model = conversational_model.to(device)\n",
    "conversational_model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Recipes: {len(df)}, Index size: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b84d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5155414 recipes\n",
      "Trimmed to 10000 recipes for small dataset\n"
     ]
    }
   ],
   "source": [
    "small = True  # Set to True to use a smaller dataset for testing\n",
    "\n",
    "# Load the recipe data\n",
    "df = pd.read_csv('../datasets/Cleaned/clean_recipes.csv')\n",
    "print(f\"Loaded {len(df)} recipes\")\n",
    "\n",
    "# trim to first 10000 entries to match index\n",
    "if small == True:\n",
    "    df = df.head(10000)\n",
    "    print(f\"Trimmed to {len(df)} recipes for small dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc92394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index with 10000 vectors\n"
     ]
    }
   ],
   "source": [
    "# Load the FAISS index\n",
    "if small:\n",
    "    index = faiss.read_index('../VectorDB/recipe_index_xsmol.faiss')\n",
    "else:\n",
    "    index = faiss.read_index('../VectorDB/recipe_index.faiss')\n",
    "print(f\"Loaded index with {index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98f240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding model\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Loaded embedding model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231e13b",
   "metadata": {},
   "source": [
    "Define functions for rag implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_recipes(query, k=3):\n",
    "    \"\"\"Retrieve top-k similar recipes\"\"\"\n",
    "    q_emb = embedding_model.encode([query]).astype('float32')\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    scores, indices = index.search(q_emb, k)\n",
    "    \n",
    "    results = []\n",
    "    for idx, score in zip(indices[0], scores[0]):\n",
    "        results.append({\n",
    "            'response': df.iloc[idx]['response'],\n",
    "            'similarity': float(score)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def rag_answer(query, k=2, max_new_tokens=150):\n",
    "    \"\"\"Generate answer using RAG\"\"\"\n",
    "    \n",
    "    # Retrieve\n",
    "    retrieved = retrieve_recipes(query, k=k)\n",
    "    \n",
    "    # Build context\n",
    "    context = \"Similar recipes:\\n\"\n",
    "    for i, rec in enumerate(retrieved, 1):\n",
    "        context += f\"{i}. {rec['response']}\\n\"\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"The following is a conversation between a user and a helpful cooking assistant.\n",
    "\n",
    "{context}\n",
    "\n",
    "User: {query}\n",
    "Assistant:\"\"\"\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = conversational_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract answer\n",
    "    if \"Answer:\" in response:\n",
    "        answer = response.split(\"Answer:\")[-1].strip()\n",
    "    else:\n",
    "        answer = response\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23630835",
   "metadata": {},
   "source": [
    "Test the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I have chicken and rice, what can I make?\"\n",
    "print(f\"\\nQuery: {query}\\n\")\n",
    "answer = rag_answer(query, k=3)\n",
    "print(f\"\\nAnswer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearnvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
